#!/usr/bin/env python3

import subprocess
import sys
import platform


def get_memory_size():
    system = platform.system()
    if system == "Darwin":  # macOS
        meminfo = subprocess.check_output(["sysctl", "-n", "hw.memsize"]).decode(
            "utf-8"
        )
        memory_in_bytes = int(meminfo)
        memory_in_gb = memory_in_bytes / (1024**3)
    elif system == "Linux":
        with open("/proc/meminfo", "r") as f:
            lines = f.readlines()
            for line in lines:
                if line.startswith("MemTotal:"):
                    memory_in_kb = int(line.split()[1])
                    memory_in_gb = memory_in_kb / 1024.0 / 1024.0
                    break
    else:
        raise NotImplementedError("This script only supports macOS and Linux.")
    return memory_in_gb


def main():
    model = "deepseek-coder-v2" if get_memory_size() > 12.0 else "codeqwen:chat"
    command = ["ollama", "run", model] + sys.argv[1:]
    print("Running model:", model, "\n")
    subprocess.run(command)


if __name__ == "__main__":
    main()
